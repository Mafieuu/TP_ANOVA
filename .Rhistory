# Suppression des fichiers HTML
#unlink("graphs/", recursive = TRUE)
for (f in  list.files(pattern = "html$"))
unlink(f)
# Vérification des dépendances
source("verification_installation_dependances.R")
# Recréer tous les chapitres
chapitres <- list.files(pattern = "Rmd$")
for (f in chapitres) {
set.seed(100);
rmarkdown::render(f, envir = new.env())
}
# Générer le PDF
source("make_pdf.R")
# Suppression des fichiers HTML
#unlink("graphs/", recursive = TRUE)
for (f in  list.files(pattern = "html$"))
unlink(f)
# Vérification des dépendances
source("verification_installation_dependances.R")
# Recréer tous les chapitres
chapitres <- list.files(pattern = "Rmd$")
for (f in chapitres) {
set.seed(100);
rmarkdown::render(f, envir = new.env())
}
# Générer le PDF
source("make_pdf.R")
# Suppression des fichiers HTML
#unlink("graphs/", recursive = TRUE)
for (f in  list.files(pattern = "html$"))
unlink(f)
# Vérification des dépendances
source("verification_installation_dependances.R")
# Recréer tous les chapitres
chapitres <- list.files(pattern = "Rmd$")
for (f in chapitres) {
set.seed(100);
rmarkdown::render(f, envir = new.env())
}
# Générer le PDF
source("make_pdf.R")
# Suppression des fichiers HTML
#unlink("graphs/", recursive = TRUE)
for (f in  list.files(pattern = "html$"))
unlink(f)
# Vérification des dépendances
source("verification_installation_dependances.R")
# Recréer tous les chapitres
chapitres <- list.files(pattern = "Rmd$")
for (f in chapitres) {
set.seed(100);
rmarkdown::render(f, envir = new.env())
}
# Générer le PDF
source("make_pdf.R")
# Suppression des fichiers HTML
#unlink("graphs/", recursive = TRUE)
for (f in  list.files(pattern = "html$"))
unlink(f)
# Vérification des dépendances
source("verification_installation_dependances.R")
# Recréer tous les chapitres
chapitres <- list.files(pattern = "Rmd$")
for (f in chapitres) {
set.seed(100);
rmarkdown::render(f, envir = new.env())
}
# Générer le PDF
source("make_pdf.R")
# Suppression des fichiers HTML
#unlink("graphs/", recursive = TRUE)
for (f in  list.files(pattern = "html$"))
unlink(f)
# Vérification des dépendances
source("verification_installation_dependances.R")
# Recréer tous les chapitres
chapitres <- list.files(pattern = "Rmd$")
for (f in chapitres) {
set.seed(100);
rmarkdown::render(f, envir = new.env())
}
# Générer le PDF
source("make_pdf.R")
require(xml2)
require(stringr)
## Page d'accueil
index <- read_html("index.html", encoding = "UTF-8")
res <- as.character(xml_find_first(index, ".//article"))
## Identifier les chapitres
divs <- xml_find_all(index, ".//div")
for (div in divs)
if (!is.na(xml_attr(div, 'id')))
if (xml_attr(div, 'id') == 'tdm')
tdm <- div
chapitres <- unique(xml_attr(xml_find_all(tdm, ".//a"), 'href'))
chapitres <- chapitres[str_starts(chapitres, "#", negate = TRUE)]
## Récupérer le contenu de chaque chapitre
for (chap in chapitres) {
page <- read_html(chap, encoding = "UTF-8")
contenu <- as.character(xml_find_first(page, ".//article"))
rac <- str_sub(chap, 1, -6)
contenu <- str_replace_all(contenu, 'id="TOC', 'class="TOC')
contenu <- str_replace_all(contenu, 'id="', paste0('id="', rac, "_"))
contenu <- str_replace_all(contenu, 'href="#', paste0('href="#', rac, "_"))
contenu <- str_replace_all(contenu, '<article>', paste0('<article id="', rac, '">'))
res <- paste(res, contenu, sep="\n")
}
# Quelques ajustements
res <- str_replace_all(res, '&#13;', '')
for (chap in chapitres) {
rac <- str_sub(chap, 1, -6)
res <- str_replace_all(res, paste0('href="', chap, '#'), paste0('href="#', rac, '_'))
res <- str_replace_all(res, paste0('href="', chap, '"'), paste0('href="#', rac, '"'))
}
## Export final
before <- paste(readLines("include/pdf_before.html", encoding = "UTF-8"), collapse = "\n")
after <- paste(readLines("include/pdf_after.html", encoding = "UTF-8"), collapse = "\n")
res <- paste(before, res, after, sep="\n")
res <- str_replace_all(res, "\r", "")
cat(res, file = file("analyse-R.html", encoding = "UTF-8"), sep="\n")
## Génération du PDF
system('prince analyse-R.html --javascript')
`0.BASE.TRAVAUX.PRATIQUES.ANOVA.ISE2.2024.2025` <- read.csv("C:/Users/HP/Desktop/temp/Projet/anova/remake_analyseR/data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv", header=FALSE, sep=";")
View(`0.BASE.TRAVAUX.PRATIQUES.ANOVA.ISE2.2024.2025`)
library(readxl)
X0_BASE_TRAVAUX_PRATIQUES_ANOVA_ISE2_2024_2025 <- read_excel("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv")
library(readr)
X0_BASE_TRAVAUX_PRATIQUES_ANOVA_ISE2_2024_2025 <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";", escape_double = FALSE, na = "NA",
trim_ws = TRUE)
View(X0_BASE_TRAVAUX_PRATIQUES_ANOVA_ISE2_2024_2025)
library(readr)
X0_BASE_TRAVAUX_PRATIQUES_ANOVA_ISE2_2024_2025 <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";", escape_double = FALSE, na = "NA",
trim_ws = TRUE)
View(X0_BASE_TRAVAUX_PRATIQUES_ANOVA_ISE2_2024_2025)
library(readr)
X0_BASE_TRAVAUX_PRATIQUES_ANOVA_ISE2_2024_2025 <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";", escape_double = FALSE, na = "NA",
trim_ws = TRUE)
individu_2 <- data[2, ]
library(readr)
data <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";", escape_double = FALSE, na = "NA",
trim_ws = TRUE)
individu_2 <- data[2, ]
tableau_individu_2 <- tbl_summary(individu_2)
library(readr)
library(gtsummary)
individu_2 <- data[2, ]
tableau_individu_2 <- tbl_summary(individu_2)
tableau_individu_2
View(`0.BASE.TRAVAUX.PRATIQUES.ANOVA.ISE2.2024.2025`)
View(`0.BASE.TRAVAUX.PRATIQUES.ANOVA.ISE2.2024.2025`)
View(`0.BASE.TRAVAUX.PRATIQUES.ANOVA.ISE2.2024.2025`)
data <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";", escape_double = FALSE, na = "NA",
trim_ws = TRUE)
individu_2 <- data[2, ]
individu_2_df <- as.data.frame(t(individu_2))
knitr::kable(individu_2, caption = "Valeurs de l'individu numéro 2 par variable")
data <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";",
trim_ws = TRUE)
View(`0.BASE.TRAVAUX.PRATIQUES.ANOVA.ISE2.2024.2025`)
data <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";",
trim_ws = TRUE)
quant_vars <- sapply(data, is.numeric)
quantitative_stats <- data.frame(
Variable = names(data)[quant_vars],
Valeurs_manquantes = colSums(is.na(data[, quant_vars])),
Minimum = sapply(data[, quant_vars], min, na.rm = TRUE),
Maximum = sapply(data[, quant_vars], max, na.rm = TRUE),
Moyenne = sapply(data[, quant_vars], mean, na.rm = TRUE),
Variance = sapply(data[, quant_vars], var, na.rm = TRUE)
)
knitr::kable(quantitative_stats, caption = "Statistiques des Variables Quantitatives")
qual_vars <- sapply(data, is.factor) | sapply(data, is.character)
qualitative_table <- data.frame(
Variable = names(data)[qual_vars],
Facteurs = sapply(data[, qual_vars], function(x) paste(unique(x), collapse = ", ")),
Valeurs_manquantes = colSums(is.na(data[, qual_vars]))
)
knitr::kable(qualitative_table, caption = "Variables Qualitatives, Facteurs et Nombre de Valeurs Manquantes")
require(xml2)
require(stringr)
## Page d'accueil
index <- read_html("index.html", encoding = "UTF-8")
res <- as.character(xml_find_first(index, ".//article"))
## Identifier les chapitres
divs <- xml_find_all(index, ".//div")
for (div in divs)
if (!is.na(xml_attr(div, 'id')))
if (xml_attr(div, 'id') == 'tdm')
tdm <- div
chapitres <- unique(xml_attr(xml_find_all(tdm, ".//a"), 'href'))
chapitres <- chapitres[str_starts(chapitres, "#", negate = TRUE)]
## Récupérer le contenu de chaque chapitre
for (chap in chapitres) {
page <- read_html(chap, encoding = "UTF-8")
contenu <- as.character(xml_find_first(page, ".//article"))
rac <- str_sub(chap, 1, -6)
contenu <- str_replace_all(contenu, 'id="TOC', 'class="TOC')
contenu <- str_replace_all(contenu, 'id="', paste0('id="', rac, "_"))
contenu <- str_replace_all(contenu, 'href="#', paste0('href="#', rac, "_"))
contenu <- str_replace_all(contenu, '<article>', paste0('<article id="', rac, '">'))
res <- paste(res, contenu, sep="\n")
}
# Quelques ajustements
res <- str_replace_all(res, '&#13;', '')
for (chap in chapitres) {
rac <- str_sub(chap, 1, -6)
res <- str_replace_all(res, paste0('href="', chap, '#'), paste0('href="#', rac, '_'))
res <- str_replace_all(res, paste0('href="', chap, '"'), paste0('href="#', rac, '"'))
}
## Export final
before <- paste(readLines("include/pdf_before.html", encoding = "UTF-8"), collapse = "\n")
after <- paste(readLines("include/pdf_after.html", encoding = "UTF-8"), collapse = "\n")
res <- paste(before, res, after, sep="\n")
res <- str_replace_all(res, "\r", "")
cat(res, file = file("analyse-R.html", encoding = "UTF-8"), sep="\n")
## Génération du PDF
system('prince analyse-R.html --javascript')
#unlink("graphs/", recursive = TRUE)
for (f in  list.files(pattern = "html$"))
unlink(f)
# Recréer tous les chapitres
chapitres <- list.files(pattern = "Rmd$")
for (f in chapitres) {
set.seed(100);
rmarkdown::render(f, envir = new.env())
}
# Générer le PDF
source("make_pdf.R")
# Générer le PDF
source("make_pdf.R")
source("options_communes.R")
library(readr)
library(ggplot2)
library(corrplot)
library(dplyr)
data <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";",
trim_ws = TRUE)
individu_2 <- data[2, ]
individu_2_df <- as.data.frame(t(individu_2))
knitr::kable(individu_2, caption = "Valeurs de l'individu numéro 2 par variable",,row.names = FALSE)
library(dplyr)
library(forcats)  # Pour reorder_levels
data <- data %>%
mutate(
# Recodage et ordonnancement de l’enracinement
Enracinement = fct_relevel(recode_factor(Enracinement,
"Faible" = "Faible",
"Moyen" = "Moyen",
"Tres.fort" = "Très Fort",
"Fort" = "Fort"),
"Faible", "Moyen", "Fort", "Très Fort"),
# Recodage et ordonnancement de la parcelle
Parcelle = fct_relevel(recode_factor(Parcelle,
"Nord" = "Nord",
"Sud" = "Sud",
"Est" = "Est",
"Ouest" = "Ouest"),
"Est", "Ouest", "Nord", "Sud"),
)
write_delim(data, "data/data_corrige.csv", delim = ";")
write_delim(data, "data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv", delim = ";")
head_data <- head(data)
# Affichage du tableau avec knitr
knitr::kable(head_data, caption = "Premières Lignes de la Base de Données", row.names = FALSE)
quant_vars <- sapply(data, is.numeric)
quantitative_stats <- data.frame(
Variable = names(data)[quant_vars],
valeur_NA = colSums(is.na(data[, quant_vars])),
Moyenne = sapply(data[, quant_vars], mean, na.rm = TRUE),
Variance = sapply(data[, quant_vars], var, na.rm = TRUE)
)
knitr::kable(quantitative_stats, caption = "Statistiques des Variables Quantitatives",row.names = FALSE)
qual_vars <- sapply(data, is.factor) | sapply(data, is.character)
qualitative_table <- data.frame(
Variable = names(data)[qual_vars],
Facteurs = sapply(data[, qual_vars], function(x) paste(unique(x), collapse = ", ")),
Fréquences = sapply(data[, qual_vars], function(x) paste(
names(table(x)), "(", table(x), ")", collapse = ", "
)),
Valeurs_manquantes = colSums(is.na(data[, qual_vars]))
)
rownames(qualitative_table) <- NULL
knitr::kable(qualitative_table, caption = "Variables Qualitatives, Facteurs, Fréquences et Nombre de Valeurs Manquantes")
qualitative_vars <- c("Couleur", "Germination.epi", "Enracinement", "Verse",
"Attaque", "Parcelle", "Verse.Traitement")
# Définition de la fonction de calcul du coefficient de corrélation
rapport_corr <- function(x, y) {
# x est une variable qualitative
# y est une variable quantitative
# Suppression des valeurs manquantes dans x et y
complete_cases <- complete.cases(x, y)
x <- x[complete_cases]
y <- y[complete_cases]
somme <- 0
niveaux <- unique(x)
for (facteur in niveaux) {
ind <- which(x == facteur)
classe <- y[ind]
somme <- somme + length(classe) * sum((mean(classe, na.rm = TRUE) - mean(y, na.rm = TRUE))^2)
}
y_ecart <- sum((y - mean(y, na.rm = TRUE))^2)
rc <- somme / y_ecart
return(rc)
}
# Création du tableau de corrélation
correlation_table <- data.frame(Qualitative = qualitative_vars) %>%
rowwise() %>%
mutate(Correlation = rapport_corr(data[[Qualitative]], data$Nb.grains)) %>%
ungroup()
# Affichage du tableau avec knitr
rownames(correlation_table) <- NULL
knitr::kable(correlation_table, caption = "Coefficient de Corrélation entre Variables Qualitatives et la Masse")
library(ggplot2)
library(viridis)  #  couleurs plus elegent
ggplot(correlation_table, aes(x = reorder(Qualitative, Correlation), y = Correlation, fill = Correlation)) +
geom_bar(stat = "identity", width = 0.6, color = "black") +  # Bordures noires pour plus de contraste
coord_flip() +  # Meilleure lisibilité
theme_minimal(base_size = 14) +  # Style épuré avec texte plus grand
scale_fill_viridis_c(option = "magma", direction = -1) +  # Palette de couleurs esthétiques
labs(title = "Rapport de Corrélation entre Variables Qualitatives et Nombre de Grains",
x = "Variables Qualitatives",
y = "Coefficient de Corrélation") +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "right",
panel.grid.major = element_blank(),  # Supprime les grandes lignes de grille pour plus de clarté
panel.grid.minor = element_blank())
source("options_communes.R")
library(readr)
library(ggplot2)
library(corrplot)
library(gridExtra)
data <- read_delim("data/0.BASE TRAVAUX PRATIQUES ANOVA ISE2 2024-2025.csv",
delim = ";",
trim_ws = TRUE)
# Calcul de la moyenne de la variable  en ignorant les valeurs manquantes
mean_value <- mean(data$Nb.grains, na.rm = TRUE)
data$Nb.grains[is.na(data$Nb.grains)] <- mean_value
# Vérification
# Doit être égal à 0
if (sum(is.na(data$NB.grain)) ==0){
# Sauvegarde
write_delim(data, "data/data_corrige.csv", delim = ";")
cat("Operation réussi")
}
library(dplyr)
library(ggplot2)
# Fonction améliorée pour générer un histogramme des effectifs trié en ordre croissant
histogramme_effectifs <- function(data, variable) {
# Calcul des effectifs et tri par ordre croissant
effectifs <- data %>%
count(.data[[variable]]) %>%
arrange(n)  # Tri par ordre croissant
# Convertir la variable en facteur avec l'ordre croissant des effectifs
data[[variable]] <- factor(data[[variable]], levels = effectifs[[variable]])
# Création de l'histogramme avec les effectifs affichés
ggplot(data, aes(x = .data[[variable]], fill = .data[[variable]])) +
geom_bar() +
geom_text(stat = "count", aes(label = ..count..), vjust = -0.3, size = 5) +
theme_minimal() +
labs(
title = paste("Histogramme des effectifs pour", variable),
x = variable,
y = "Effectif"
) +
theme(
legend.position = "none",        # Suppression de la légende
plot.title = element_text(hjust = 0.5, face = "bold", size = 14),  # Titre centré et en gras
axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Rotation du texte de l’axe X
axis.text.y = element_text(size = 12),
axis.title.x = element_text(size = 13, face = "bold"),
axis.title.y = element_text(size = 13, face = "bold")
) +
scale_fill_manual(values = c("#A63946", "#E0A261", "#2A2E8F", "#26C653", "#8A5A8F", "#FF5A8F"))
}
histogramme_effectifs(data, "Parcelle")
histogramme_effectifs(data, "Enracinement")
source("options_communes.R")
library(readr)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(readr)
library(ggcorrplot)
library(lsr)
library(plotly)
library(GGally)
library(rstatix)
data <- read_delim("data/data_corrige.csv",
delim = ";",
trim_ws = TRUE)
ggplot(data, aes(y = Nb.grains)) +
geom_boxplot(outlier.color = "red", outlier.shape = 16, outlier.size = 3, fill = "skyblue") +
theme_minimal() +
labs(title = "Distribution de Nb.grains",
y = "Nombre de grains") +
theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
axis.text = element_text(size = 12),
axis.title = element_text(size = 13))
data_group = data |>
group_by(Parcelle) |>
get_summary_stats(Nb.grains, type = "mean_sd")
# kable(data_group, caption = "Nombre de grain moyenne pour chaque modalité des facteurs")
ggplot(data_group) +
aes(x = reorder(Parcelle, mean), y = mean, fill = Parcelle) +
geom_col() +
scale_fill_hue(direction = 1) +
theme_minimal() +
labs(title = "Nombre de grain moyenne par Parcelle", x = "Parcelle", y = "Moyenne nombre de grain")
# Comparer "Parcelle" et "Nb.grains"
ggplot(data, aes(x = Parcelle, y = Nb.grains)) +
geom_boxplot(fill = "skyblue", color = "black") +
theme_minimal() +
ggtitle(" Nombre de grains par Parcelle") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Parcelle", y = "nombre de grains")
data %>%
group_by(Parcelle) %>%
identify_outliers(Nb.grains)
data_group = data |>
group_by( Enracinement) |>
get_summary_stats(Nb.grains, type = "mean_sd")
# kable(data_group, caption = "Nombre de grain moyenne pour chaque modalité des facteurs")
ggplot(data_group) +
aes(x = reorder(Enracinement, mean), y = mean, fill = Enracinement) +
geom_col() +
scale_fill_hue(direction = 1) +
theme_minimal() +
labs(title = "Nombre de grain moyenne par niveau d'enracinement", x = "Enracinement", y = "Moyenne nombre de grain")
# Comparer "Enracinement" et "Nb.grains"
ggplot(data, aes(x = Enracinement, y = Nb.grains)) +
geom_boxplot(fill = "gold", color = "black") +
theme_minimal() +
ggtitle("Comparaison de Nb des grains par Enracinement") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Enracinement", y = "Nb des grains")
data %>%
group_by(Parcelle, Enracinement) %>%
get_summary_stats(Nb.grains, type = "mean_sd")
library("ggpubr")
bxp <- ggboxplot(
data, x = "Enracinement", y = "Nb.grains",
color = "Parcelle", palette = "jco"
)
bxp
data %>%
group_by(Parcelle, Enracinement) %>%
identify_outliers(Nb.grains)
# Identifier les outliers
outliers <- data %>%
group_by(Parcelle, Enracinement) %>%
identify_outliers(Nb.grains)
data_clean <- data %>%
anti_join(outliers %>% filter(is.extreme), by = c("Parcelle", "Enracinement", "Nb.grains"))
cat("Nombre de lignes après suppression :", nrow(data_clean), "\n")
write_delim(data_clean, "data/data_corrige.csv", delim = ";")
data <-data_clean
cat("Fichier sauvegardé avec succès.")
data %>%
group_by(Parcelle, Enracinement) %>%
identify_outliers(Nb.grains)
source("options_communes.R")
library(readr)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(readr)
library(ggcorrplot)
library(lsr)
library(dplyr)
library(plotly)
library(GGally)
library(rstatix)
library(rcompanion)
data <- read_delim("data/data_corrige.csv",
delim = ";",
trim_ws = TRUE)
shapiro.test(data$Nb.grains)
shapiro.test(log(data$Nb.grains))
library("MASS")
boxcox(data$Nb.grains ~ 1, lambda = seq(-2, 2, 0.01))
lambda = 1.95
data$Nb.grain_bc = (data$Nb.grains^lambda - 1)/lambda
shapiro.test(data$Nb.grain_bc)
library(ggpubr)
shapiro_results <- data %>%
group_by(Enracinement) %>%
summarise(p_value = shapiro.test(Nb.grains)$p.value, .groups = "drop")
# Afficher les résultats
print(shapiro_results)
# Graphique QQ-Plot avec facettes
ggqqplot(data, "Nb.grains", ggtheme = theme_bw()) +
facet_grid(Parcelle ~ Enracinement)
data %>% levene_test(Nb.grains ~ Enracinement*Parcelle)
scheirerRayHare(Nb.grains ~ Enracinement + Parcelle + Enracinement:Parcelle, data = data)
library(FSA)
dunnTest(Nb.grains ~ Parcelle, data = data, method = "bonferroni")
library(ggplot2)
ggplot(data, aes(x = Parcelle, y = Nb.grains, fill = Parcelle)) +
geom_boxplot() +
theme_bw() +
ggtitle("Comparaison du nombre de grains par Parcelle")
# Générer le PDF
source("make_pdf.R")
